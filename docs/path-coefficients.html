<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Structural Equation Modeling for Ecology and Evolution</title>
  <meta name="description" content="Structural Equation Modeling for Ecology and Evolution">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Structural Equation Modeling for Ecology and Evolution" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://jebyrnes.github.io/sem" />
  
  
  <meta name="github-repo" content="jebyrnes/sem" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Structural Equation Modeling for Ecology and Evolution" />
  <meta name="twitter:site" content="@jebyrnes" />
  
  

<meta name="author" content="Jarrett Byrnes">
<meta name="author" content="Jon Lefcheck">
<meta name="author" content="James Grace">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="why-structural-equation-modeling-1.html">
<link rel="next" href="global-estimation-and-piecewisesem.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="part"><span><b>I Jarrettâ€™s Suggestion for a TOC</b></span></li>
<li class="part"><span><b>II The Basics</b></span></li>
<li class="chapter" data-level="1" data-path="why-structural-equation-modeling.html"><a href="why-structural-equation-modeling.html"><i class="fa fa-check"></i><b>1</b> Why Structural Equation Modeling?</a><ul>
<li class="chapter" data-level="1.1" data-path="why-structural-equation-modeling.html"><a href="why-structural-equation-modeling.html#the-world-we-grew-up-in"><i class="fa fa-check"></i><b>1.1</b> The world we grew up in</a></li>
<li class="chapter" data-level="1.2" data-path="why-structural-equation-modeling.html"><a href="why-structural-equation-modeling.html#exploring-systems"><i class="fa fa-check"></i><b>1.2</b> Exploring Systems</a></li>
<li class="chapter" data-level="1.3" data-path="why-structural-equation-modeling.html"><a href="why-structural-equation-modeling.html#history"><i class="fa fa-check"></i><b>1.3</b> History</a></li>
<li class="chapter" data-level="1.4" data-path="why-structural-equation-modeling.html"><a href="why-structural-equation-modeling.html#one-car-many-engines"><i class="fa fa-check"></i><b>1.4</b> One Car, Many Engines</a></li>
<li class="chapter" data-level="1.5" data-path="why-structural-equation-modeling.html"><a href="why-structural-equation-modeling.html#the-r-infrastructure"><i class="fa fa-check"></i><b>1.5</b> The R infrastructure</a></li>
<li class="chapter" data-level="1.6" data-path="why-structural-equation-modeling.html"><a href="why-structural-equation-modeling.html#the-example-data-sets-in-this-book"><i class="fa fa-check"></i><b>1.6</b> The example data sets in this book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-language-of-sems.html"><a href="the-language-of-sems.html"><i class="fa fa-check"></i><b>2</b> The Language of SEMs</a><ul>
<li class="chapter" data-level="2.1" data-path="the-language-of-sems.html"><a href="the-language-of-sems.html#boxes-circles-and-hexagons-oh-my"><i class="fa fa-check"></i><b>2.1</b> Boxes, Circles, and Hexagons, oh my!</a></li>
<li class="chapter" data-level="2.2" data-path="the-language-of-sems.html"><a href="the-language-of-sems.html#paths"><i class="fa fa-check"></i><b>2.2</b> Paths</a></li>
<li class="chapter" data-level="2.3" data-path="the-language-of-sems.html"><a href="the-language-of-sems.html#recursive-and-non-recursive-models"><i class="fa fa-check"></i><b>2.3</b> Recursive and non-recursive models</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="building-multivariate-causal-models.html"><a href="building-multivariate-causal-models.html"><i class="fa fa-check"></i><b>3</b> Building Multivariate Causal Models</a><ul>
<li class="chapter" data-level="3.1" data-path="building-multivariate-causal-models.html"><a href="building-multivariate-causal-models.html#granger-causality"><i class="fa fa-check"></i><b>3.1</b> Granger Causality</a></li>
<li class="chapter" data-level="3.2" data-path="building-multivariate-causal-models.html"><a href="building-multivariate-causal-models.html#a-primer-on-causality-in-models-sensu-pearl"><i class="fa fa-check"></i><b>3.2</b> A primer on Causality in models (sensu Pearl)</a></li>
<li class="chapter" data-level="3.3" data-path="building-multivariate-causal-models.html"><a href="building-multivariate-causal-models.html#causality-and-unmeasured-variables"><i class="fa fa-check"></i><b>3.3</b> Causality and Unmeasured variables</a></li>
<li class="chapter" data-level="3.4" data-path="building-multivariate-causal-models.html"><a href="building-multivariate-causal-models.html#conditional-independence-and-directed-separation"><i class="fa fa-check"></i><b>3.4</b> Conditional Independence and Directed Separation</a></li>
</ul></li>
<li class="part"><span><b>III Fitting and Evaluating Models</b></span></li>
<li class="chapter" data-level="4" data-path="fitting-with-likelihood.html"><a href="fitting-with-likelihood.html"><i class="fa fa-check"></i><b>4</b> Fitting with Likelihood</a><ul>
<li class="chapter" data-level="4.1" data-path="fitting-with-likelihood.html"><a href="fitting-with-likelihood.html#fundamentals-of-technique"><i class="fa fa-check"></i><b>4.1</b> Fundamentals of technique</a></li>
<li class="chapter" data-level="4.2" data-path="fitting-with-likelihood.html"><a href="fitting-with-likelihood.html#how-to-fit"><i class="fa fa-check"></i><b>4.2</b> How to fit</a></li>
<li class="chapter" data-level="4.3" data-path="fitting-with-likelihood.html"><a href="fitting-with-likelihood.html#model-diagnostics"><i class="fa fa-check"></i><b>4.3</b> Model Diagnostics</a></li>
<li class="chapter" data-level="4.4" data-path="fitting-with-likelihood.html"><a href="fitting-with-likelihood.html#evaluation-of-a-fit-model"><i class="fa fa-check"></i><b>4.4</b> Evaluation of a Fit Model</a></li>
<li class="chapter" data-level="4.5" data-path="fitting-with-likelihood.html"><a href="fitting-with-likelihood.html#prediction"><i class="fa fa-check"></i><b>4.5</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="fitting-with-piecewise-approaches.html"><a href="fitting-with-piecewise-approaches.html"><i class="fa fa-check"></i><b>5</b> Fitting with piecewise Approaches</a><ul>
<li class="chapter" data-level="5.1" data-path="fitting-with-piecewise-approaches.html"><a href="fitting-with-piecewise-approaches.html#fundamentals-of-technique-1"><i class="fa fa-check"></i><b>5.1</b> Fundamentals of technique</a></li>
<li class="chapter" data-level="5.2" data-path="fitting-with-piecewise-approaches.html"><a href="fitting-with-piecewise-approaches.html#how-to-fit-1"><i class="fa fa-check"></i><b>5.2</b> How to fit</a></li>
<li class="chapter" data-level="5.3" data-path="fitting-with-piecewise-approaches.html"><a href="fitting-with-piecewise-approaches.html#model-diagnostics-1"><i class="fa fa-check"></i><b>5.3</b> Model Diagnostics</a></li>
<li class="chapter" data-level="5.4" data-path="fitting-with-piecewise-approaches.html"><a href="fitting-with-piecewise-approaches.html#evaluation-of-a-fit-model-1"><i class="fa fa-check"></i><b>5.4</b> Evaluation of a Fit Model</a></li>
<li class="chapter" data-level="5.5" data-path="fitting-with-piecewise-approaches.html"><a href="fitting-with-piecewise-approaches.html#prediction-1"><i class="fa fa-check"></i><b>5.5</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="fitting-with-bayesian-approaches.html"><a href="fitting-with-bayesian-approaches.html"><i class="fa fa-check"></i><b>6</b> Fitting with Bayesian Approaches</a><ul>
<li class="chapter" data-level="6.1" data-path="fitting-with-bayesian-approaches.html"><a href="fitting-with-bayesian-approaches.html#fundamentals-of-technique-2"><i class="fa fa-check"></i><b>6.1</b> Fundamentals of technique</a></li>
<li class="chapter" data-level="6.2" data-path="fitting-with-bayesian-approaches.html"><a href="fitting-with-bayesian-approaches.html#how-to-fit-2"><i class="fa fa-check"></i><b>6.2</b> How to fit</a></li>
<li class="chapter" data-level="6.3" data-path="fitting-with-bayesian-approaches.html"><a href="fitting-with-bayesian-approaches.html#model-diagnostics-2"><i class="fa fa-check"></i><b>6.3</b> Model Diagnostics</a></li>
<li class="chapter" data-level="6.4" data-path="fitting-with-bayesian-approaches.html"><a href="fitting-with-bayesian-approaches.html#evaluation-of-a-fit-model-2"><i class="fa fa-check"></i><b>6.4</b> Evaluation of a Fit Model</a></li>
<li class="chapter" data-level="6.5" data-path="fitting-with-bayesian-approaches.html"><a href="fitting-with-bayesian-approaches.html#prediction-2"><i class="fa fa-check"></i><b>6.5</b> Prediction</a></li>
</ul></li>
<li class="part"><span><b>IV Advanced Model Components</b></span></li>
<li class="chapter" data-level="7" data-path="nonlinearities-and-nonnormality-in-sem.html"><a href="nonlinearities-and-nonnormality-in-sem.html"><i class="fa fa-check"></i><b>7</b> Nonlinearities and Nonnormality in SEM</a></li>
<li class="chapter" data-level="8" data-path="interaction-effects.html"><a href="interaction-effects.html"><i class="fa fa-check"></i><b>8</b> Interaction Effects</a></li>
<li class="chapter" data-level="9" data-path="latent-variables.html"><a href="latent-variables.html"><i class="fa fa-check"></i><b>9</b> Latent Variables</a></li>
<li class="chapter" data-level="10" data-path="composite-variables.html"><a href="composite-variables.html"><i class="fa fa-check"></i><b>10</b> Composite Variables</a></li>
<li class="chapter" data-level="11" data-path="multigroup-models.html"><a href="multigroup-models.html"><i class="fa fa-check"></i><b>11</b> Multigroup Models</a></li>
<li class="chapter" data-level="12" data-path="categorical-predictors.html"><a href="categorical-predictors.html"><i class="fa fa-check"></i><b>12</b> Categorical Predictors</a></li>
<li class="part"><span><b>V Handling Correlation from Unmodled Variables</b></span></li>
<li class="chapter" data-level="13" data-path="mixed-models-and-sem.html"><a href="mixed-models-and-sem.html"><i class="fa fa-check"></i><b>13</b> Mixed Models and SEM</a></li>
<li class="chapter" data-level="14" data-path="phylogenetic-sem.html"><a href="phylogenetic-sem.html"><i class="fa fa-check"></i><b>14</b> Phylogenetic SEM</a></li>
<li class="chapter" data-level="15" data-path="temporal-autocorrelation-in-sem.html"><a href="temporal-autocorrelation-in-sem.html"><i class="fa fa-check"></i><b>15</b> Temporal Autocorrelation in SEM</a></li>
<li class="chapter" data-level="16" data-path="spatial-autocorrelation-in-sem.html"><a href="spatial-autocorrelation-in-sem.html"><i class="fa fa-check"></i><b>16</b> Spatial Autocorrelation in SEM</a></li>
<li class="part"><span><b>VI Example Analyses</b></span></li>
<li class="part"><span><b>VII Sample Chapters Below Here for Now</b></span></li>
<li class="chapter" data-level="17" data-path="why-structural-equation-modeling-1.html"><a href="why-structural-equation-modeling-1.html"><i class="fa fa-check"></i><b>17</b> Why Structural Equation Modeling</a><ul>
<li class="chapter" data-level="17.1" data-path="why-structural-equation-modeling-1.html"><a href="why-structural-equation-modeling-1.html#the-world-we-grew-up-in-1"><i class="fa fa-check"></i><b>17.1</b> The World We Grew Up In</a></li>
<li class="chapter" data-level="17.2" data-path="why-structural-equation-modeling-1.html"><a href="why-structural-equation-modeling-1.html#exploring-systems-1"><i class="fa fa-check"></i><b>17.2</b> Exploring Systems</a></li>
<li class="chapter" data-level="17.3" data-path="why-structural-equation-modeling-1.html"><a href="why-structural-equation-modeling-1.html#one-car-many-engines-1"><i class="fa fa-check"></i><b>17.3</b> One Car, Many Engines</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="path-coefficients.html"><a href="path-coefficients.html"><i class="fa fa-check"></i><b>18</b> Path Coefficients</a><ul>
<li class="chapter" data-level="18.1" data-path="path-coefficients.html"><a href="path-coefficients.html#unstandardized-and-standardized-coefficients"><i class="fa fa-check"></i><b>18.1</b> 1.1 Unstandardized and Standardized Coefficients</a></li>
<li class="chapter" data-level="18.2" data-path="path-coefficients.html"><a href="path-coefficients.html#scale-standardization"><i class="fa fa-check"></i><b>18.2</b> 1.2 Scale Standardization</a></li>
<li class="chapter" data-level="18.3" data-path="path-coefficients.html"><a href="path-coefficients.html#range-standardization"><i class="fa fa-check"></i><b>18.3</b> 1.3 Range Standardization</a></li>
<li class="chapter" data-level="18.4" data-path="path-coefficients.html"><a href="path-coefficients.html#binomial-response-models"><i class="fa fa-check"></i><b>18.4</b> 1.4 Binomial Response Models</a></li>
<li class="chapter" data-level="18.5" data-path="path-coefficients.html"><a href="path-coefficients.html#scaling-to-other-non-normal-distributions"><i class="fa fa-check"></i><b>18.5</b> 1.5 Scaling to Other Non-Normal Distributions</a></li>
<li class="chapter" data-level="18.6" data-path="path-coefficients.html"><a href="path-coefficients.html#references"><i class="fa fa-check"></i><b>18.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html"><i class="fa fa-check"></i><b>19</b> Global Estimation and PiecewiseSEM</a><ul>
<li class="chapter" data-level="19.1" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#what-is-covariance"><i class="fa fa-check"></i><b>19.1</b> 1.1 What is (Co)variance?</a></li>
<li class="chapter" data-level="19.2" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#regression-coefficients"><i class="fa fa-check"></i><b>19.2</b> 1.2 Regression Coefficients</a><ul>
<li class="chapter" data-level="19.2.1" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#rule-1-unspecified-relationships-among-exogenous-variables-are-simply-their-bivariate-correlations."><i class="fa fa-check"></i><b>19.2.1</b> Rule 1: Unspecified relationships among exogenous variables are simply their bivariate correlations.</a></li>
<li class="chapter" data-level="19.2.2" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#rule-2-when-two-variables-are-connected-by-a-single-path-the-coefficient-of-that-path-is-the-regression-coefficient."><i class="fa fa-check"></i><b>19.2.2</b> Rule 2: When two variables are connected by a single path, the coefficient of that path is the regression coefficient.</a></li>
<li class="chapter" data-level="19.2.3" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#rule-3-the-strength-of-a-compound-path-one-that-includes-multiple-links-is-the-product-of-the-individual-coefficients."><i class="fa fa-check"></i><b>19.2.3</b> Rule 3: The strength of a compound path (one that includes multiple links) is the product of the individual coefficients.</a></li>
<li class="chapter" data-level="19.2.4" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#rule-4.-when-variables-are-connected-by-more-than-one-pathway-each-pathway-is-the-partial-regression-coefficient."><i class="fa fa-check"></i><b>19.2.4</b> Rule 4. When variables are connected by more than one pathway, each pathway is the â€˜partialâ€™ regression coefficient.</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#rule-5-errors-on-endogenous-variables-relate-the-unexplained-correlations-or-variances-arising-from-unmeasured-variables."><i class="fa fa-check"></i><b>19.3</b> Rule 5: Errors on endogenous variables relate the unexplained correlations or variances arising from unmeasured variables.</a><ul>
<li class="chapter" data-level="19.3.1" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#rule-6-unanalyzed-residual-correlations-among-two-endogenous-variables-are-their-partial-correlations."><i class="fa fa-check"></i><b>19.3.1</b> Rule 6: Unanalyzed (residual) correlations among two endogenous variables are their partial correlations.</a></li>
<li class="chapter" data-level="19.3.2" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#rule-7-the-total-effect-one-variable-has-another-is-the-sum-of-its-direct-and-indirect-effects."><i class="fa fa-check"></i><b>19.3.2</b> Rule 7: The total effect one variable has another is the sum of its direct and indirect effects.</a></li>
<li class="chapter" data-level="19.3.3" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#rule-8-the-total-effect-including-undirected-paths-is-equivalent-to-the-total-correlation."><i class="fa fa-check"></i><b>19.3.3</b> Rule 8: The total effect (including undirected paths) is equivalent to the total correlation.</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#variance-based-structural-equation-modeling"><i class="fa fa-check"></i><b>19.4</b> 1.3 Variance-based Structural Equation Modeling</a></li>
<li class="chapter" data-level="19.5" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#model-identifiability"><i class="fa fa-check"></i><b>19.5</b> 1.4 Model Identifiability</a></li>
<li class="chapter" data-level="19.6" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#goodness-of-fit-measures"><i class="fa fa-check"></i><b>19.6</b> 1.5 Goodness-of-fit Measures</a></li>
<li class="chapter" data-level="19.7" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#model-fitting-using-lavaan"><i class="fa fa-check"></i><b>19.7</b> 1.6 Model Fitting Using <em>lavaan</em></a><ul>
<li class="chapter" data-level="19.7.1" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#lavaan-vs-lm"><i class="fa fa-check"></i><b>19.7.1</b> 1.6.1 <em>lavaan</em> vs <code>lm</code></a></li>
<li class="chapter" data-level="19.7.2" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#sem-using-lavaan"><i class="fa fa-check"></i><b>19.7.2</b> 1.6.2 SEM using <em>lavaan</em></a></li>
<li class="chapter" data-level="19.7.3" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#testing-alternate-structure-using-lavaan"><i class="fa fa-check"></i><b>19.7.3</b> 1.6.3 Testing Alternate Structure using <em>lavaan</em></a></li>
</ul></li>
<li class="chapter" data-level="19.8" data-path="global-estimation-and-piecewisesem.html"><a href="global-estimation-and-piecewisesem.html#references-1"><i class="fa fa-check"></i><b>19.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="latent-variable-modeling.html"><a href="latent-variable-modeling.html"><i class="fa fa-check"></i><b>20</b> Latent Variable Modeling</a><ul>
<li class="chapter" data-level="20.1" data-path="latent-variable-modeling.html"><a href="latent-variable-modeling.html#introduction-to-latent-variable-modeling"><i class="fa fa-check"></i><b>20.1</b> 1.1 Introduction to Latent Variable Modeling</a></li>
<li class="chapter" data-level="20.2" data-path="latent-variable-modeling.html"><a href="latent-variable-modeling.html#application-of-latent-variables-to-path-models"><i class="fa fa-check"></i><b>20.2</b> 1.2 Application of Latent Variables to Path Models</a></li>
<li class="chapter" data-level="20.3" data-path="latent-variable-modeling.html"><a href="latent-variable-modeling.html#latent-variables-in-lavaan"><i class="fa fa-check"></i><b>20.3</b> 1.3 Latent Variables in <em>lavaan</em></a></li>
<li class="chapter" data-level="20.4" data-path="latent-variable-modeling.html"><a href="latent-variable-modeling.html#multi-indicator-latent-variables"><i class="fa fa-check"></i><b>20.4</b> 1.4 Multi-indicator Latent Variables</a></li>
<li class="chapter" data-level="20.5" data-path="latent-variable-modeling.html"><a href="latent-variable-modeling.html#confirmatory-factor-analysis"><i class="fa fa-check"></i><b>20.5</b> 1.6 Confirmatory Factor Analysis</a></li>
<li class="chapter" data-level="20.6" data-path="latent-variable-modeling.html"><a href="latent-variable-modeling.html#travis-grace-2010-an-example"><i class="fa fa-check"></i><b>20.6</b> 1.7 Travis &amp; Grace (2010): An Example</a></li>
<li class="chapter" data-level="20.7" data-path="latent-variable-modeling.html"><a href="latent-variable-modeling.html#references-2"><i class="fa fa-check"></i><b>20.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="composite-variables-1.html"><a href="composite-variables-1.html"><i class="fa fa-check"></i><b>21</b> Composite Variables</a><ul>
<li class="chapter" data-level="21.1" data-path="composite-variables-1.html"><a href="composite-variables-1.html#what-is-a-composite-variable"><i class="fa fa-check"></i><b>21.1</b> 1.1 What is a Composite Variable?</a></li>
<li class="chapter" data-level="21.2" data-path="composite-variables-1.html"><a href="composite-variables-1.html#constructing-a-composite-variable"><i class="fa fa-check"></i><b>21.2</b> 1.2 Constructing a Composite Variable</a></li>
<li class="chapter" data-level="21.3" data-path="composite-variables-1.html"><a href="composite-variables-1.html#grace-keeley-revisited-a-worked-example"><i class="fa fa-check"></i><b>21.3</b> 1.3 Grace &amp; Keeley Revisited: A Worked Example</a></li>
<li class="chapter" data-level="21.4" data-path="composite-variables-1.html"><a href="composite-variables-1.html#composites-in-piecewisesem"><i class="fa fa-check"></i><b>21.4</b> 1.4 Composites in <em>piecewiseSEM</em></a></li>
<li class="chapter" data-level="21.5" data-path="composite-variables-1.html"><a href="composite-variables-1.html#references-3"><i class="fa fa-check"></i><b>21.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="categorical-exogenous-variables.html"><a href="categorical-exogenous-variables.html"><i class="fa fa-check"></i><b>22</b> Categorical Exogenous Variables</a><ul>
<li class="chapter" data-level="22.1" data-path="categorical-exogenous-variables.html"><a href="categorical-exogenous-variables.html#introduction-to-exogenous-categorical-variables"><i class="fa fa-check"></i><b>22.1</b> 1.1 Introduction to Exogenous Categorical Variables</a></li>
<li class="chapter" data-level="22.2" data-path="categorical-exogenous-variables.html"><a href="categorical-exogenous-variables.html#exogenous-categorical-variables-as-marginal-means"><i class="fa fa-check"></i><b>22.2</b> 1.3 Exogenous Categorical Variables as Marginal Means</a></li>
<li class="chapter" data-level="22.3" data-path="categorical-exogenous-variables.html"><a href="categorical-exogenous-variables.html#exogenous-categorical-variables-as-marginal-means-a-worked-example"><i class="fa fa-check"></i><b>22.3</b> 1.3 Exogenous Categorical Variables as Marginal Means: A Worked Example</a></li>
<li class="chapter" data-level="22.4" data-path="categorical-exogenous-variables.html"><a href="categorical-exogenous-variables.html#endogenous-categorical-variables"><i class="fa fa-check"></i><b>22.4</b> 1.3 Endogenous Categorical Variables</a></li>
<li class="chapter" data-level="22.5" data-path="categorical-exogenous-variables.html"><a href="categorical-exogenous-variables.html#references-4"><i class="fa fa-check"></i><b>22.5</b> References</a></li>
</ul></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="agenda-and-notes-from-february-meeting.html"><a href="agenda-and-notes-from-february-meeting.html"><i class="fa fa-check"></i><b>A</b> Agenda and Notes from February Meeting</a></li>
<li class="chapter" data-level="B" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html"><i class="fa fa-check"></i><b>B</b> GLMs, Nonlinearities and C-statistics</a><ul>
<li class="chapter" data-level="B.1" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#testing-models-in-sem"><i class="fa fa-check"></i><b>B.1</b> Testing models in SEM</a></li>
<li class="chapter" data-level="B.2" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#what-is-the-c-statistic"><i class="fa fa-check"></i><b>B.2</b> What is the C-statistic</a><ul>
<li class="chapter" data-level="B.2.1" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#definition-of-d-separation-from-pearl"><i class="fa fa-check"></i><b>B.2.1</b> Definition of D-separation from Pearl</a></li>
<li class="chapter" data-level="B.2.2" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#formation-by-shipley-into-a-single-statistic"><i class="fa fa-check"></i><b>B.2.2</b> Formation by Shipley into a single statistic</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#what-is-a-c-static-or-its-ilk-for"><i class="fa fa-check"></i><b>B.3</b> What is a C-static or its ilk for</a><ul>
<li class="chapter" data-level="B.3.1" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#comparison-to-a-saturated-model"><i class="fa fa-check"></i><b>B.3.1</b> Comparison to a saturated model</a></li>
<li class="chapter" data-level="B.3.2" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#comparison-to-an-alternate-model"><i class="fa fa-check"></i><b>B.3.2</b> Comparison to an alternate model</a></li>
<li class="chapter" data-level="B.3.3" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#information-theoretic-approaches-to-model-comparison"><i class="fa fa-check"></i><b>B.3.3</b> Information theoretic approaches to model comparison</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#how-do-we-calculate-information-about-missing-links-to-integrate-into-a-c-type-statistic"><i class="fa fa-check"></i><b>B.4</b> How do we calculate information about missing links to integrate into a c-type statistic?</a><ul>
<li class="chapter" data-level="B.4.1" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#if-relationships-are-symmetrical-i.e.linear-use-current-techniques"><i class="fa fa-check"></i><b>B.4.1</b> If relationships are symmetrical, i.e.Â linear, use current techniques</a></li>
<li class="chapter" data-level="B.4.2" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#if-relationships-are-assymetric-i.e.glms-or-other-nonlinearities"><i class="fa fa-check"></i><b>B.4.2</b> If relationships are assymetric, i.e.Â GLMs or other nonlinearities</a></li>
<li class="chapter" data-level="B.4.3" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#if-relationships-are-asymmetric-and-no-known-directionality"><i class="fa fa-check"></i><b>B.4.3</b> If relationships are asymmetric and no known directionality</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#correlated-errors"><i class="fa fa-check"></i><b>B.5</b> Correlated errors</a><ul>
<li class="chapter" data-level="B.5.1" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#not-a-problem-in-a-piecewise-approach-due-to-lack-of-influence-on-parameter-estimation"><i class="fa fa-check"></i><b>B.5.1</b> Not a problem in a piecewise approach due to lack of influence on parameter estimation</a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#latent-variables-and-the-c-statistic"><i class="fa fa-check"></i><b>B.6</b> Latent variables and the C-Statistic?</a><ul>
<li class="chapter" data-level="B.6.1" data-path="glms-nonlinearities-and-c-statistics.html"><a href="glms-nonlinearities-and-c-statistics.html#can-estimate-lvs-separately-and-still-use-same-graph-approach"><i class="fa fa-check"></i><b>B.6.1</b> Can estimate lVs separately, and still use same graph approach</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Structural Equation Modeling for Ecology and Evolution</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="path-coefficients" class="section level1">
<h1><span class="header-section-number">18</span> Path Coefficients</h1>
<div id="unstandardized-and-standardized-coefficients" class="section level2">
<h2><span class="header-section-number">18.1</span> 1.1 Unstandardized and Standardized Coefficients</h2>
<p>Path (or regression) coefficients are the inferential engine behind structural equation modeling, and by extension all of linear and even some non-linear statistics (as we shall see). They relate changes in the dependent variable <span class="math inline">\(y\)</span> to changes in the independent variable <span class="math inline">\(x\)</span>, and thus act as a measure of association. In fact, you may recall from the chapter on Global Estimation that, under specific circumstances, path coefficients can be expressed as (partial) correlations, which all scientists are familiar with as a unitless measure of association. They also allow us to generate predictions for new values of <span class="math inline">\(x\)</span> and thus are useful in testing and extrapolating model results.</p>
<p>There are two kinds of regression coefficients: unstandardized, or raw coefficients, and standardized coefficients.</p>
<p>Unstandardized coefficients are the easiest to derive as they are the default values returned by all statistical programs. In short, they reflect the expected (linear) change in the response with each unit change in the predictor. For a coefficient value <span class="math inline">\(\beta = 0.5\)</span>, for example, a 1 unit change in <span class="math inline">\(x\)</span> there is, on average, an 0.5 unit change in <span class="math inline">\(y\)</span>.</p>
<p>In models with more than one independent variable (e.g., <span class="math inline">\(x1\)</span>, <span class="math inline">\(x2\)</span>, etc), the coefficient reflects the expected change in <span class="math inline">\(y\)</span> <em>given</em> the other variables in the model. This implies that the effect of one particular variable controls for the presence of other variables, generally by holding them constant at their mean. This is why such coefficients are referred to as <em>partial</em> regression coefficients, because they reflect the independent (or partial) contributions of any particular variable.</p>
<p>One tricky aspect to interpretation involves transformations. When the log-transformation is applied, for example, the relationships between the variable are no longer linear. This means that we have to change our interpretation slightly. When <span class="math inline">\(y\)</span> is log-transformed, the coefficient <span class="math inline">\(\beta\)</span> is interpreted as a 1 unit change in <span class="math inline">\(x\)</span> leads to a <span class="math inline">\((exp(\beta) - 1) \times 100%\)</span> change in <span class="math inline">\(y\)</span>. Oppositely, when the independent variable <span class="math inline">\(x\)</span> is log-transformed, <span class="math inline">\(\beta\)</span> is interpreted as a 1% change in <span class="math inline">\(x\)</span> leads to a <span class="math inline">\(\beta\)</span> increase in <span class="math inline">\(y\)</span>. Finally, when both are transformed, both are expressed in percentages: a 1% change in <span class="math inline">\(x\)</span> leads to a <span class="math inline">\((exp(\beta) - 1) \times 100%\)</span> change in <span class="math inline">\(y\)</span>. Transformations often confound intrepretation, so it is worth mentioning.</p>
<p>In contrast, standardized coefficients are expressed in equivalent units, regardless of the original measurements. Often these are in units of standard deviations of the mean (scale standardization) but, as we shall see shortly, there are other possibilities. The goal of standardization is to increase <em>comparability</em>. In other words, the magnitude of standardized coefficients can be directly compared to make inferences about the relative strength of relationships.</p>
<p>In SEM, it is often advised to report both unstandardized and standardized coefficients, because they present different and mutually exclusive information. Unstandardized coefficients contain information about both the variance <em>and</em> the mean, and thus are essential for prediction. Along these lines, they are also useful for comparing across models fit to the same variables, but using different sets of data. Because the most common form of standardization concerns scaling by the sample standard deviations, data derived from different sources have different sample variances and their standardized coefficients are not immediately comparable.</p>
<p>Unstandardized coefficients are also most related to the phenomenon of interest in the units that are relevant to the outcome. Imagine telling someone that 1 standard deviation change in nutrient input levels would result in a 6 standard deviation change in water quality. That might seem impressive until it becomes clear that the size of the dataset has reduced the sample variance, and the absoluty relationship reveals only a very tiny change in water quality with each unit change in nutrient levels. Not so impressive anymore.</p>
<p>In contrast, standardized effects are useful for comparing the relative magnitude of change associated with different paths in the same model. Care should be taken not to interpret these relationships as the â€˜proportion of variance explainedâ€™ but rather in terms of relative influence on the mean of the response.</p>
<p>By extension, standardization is necessary to compare indirect or compound effects among different paths in the same model. This is because those paths could be measured in very different units. For example, comparing the relative effect of direct vs.Â indirect pathways in a partially-mediated model.</p>
<p>In contrast, comparing the strength of indirect or compound effects across the same path in different models <em>requires</em> unstandardized coefficients, due to the issue of different sample variances raised above. Comparing the same path across different models using standardiezd coefficients would require a demonstration that the sample variances are not significantly different (or that the entire population has been sampled).</p>
<p>Thus, both standardized and unstandardized coefficients have their place. Letâ€™s now explore some of the different forms of standardization, and how they can be achieved.</p>
</div>
<div id="scale-standardization" class="section level2">
<h2><span class="header-section-number">18.2</span> 1.2 Scale Standardization</h2>
<p>The most typical implementation of standardization is placing the coefficients in units of standard deviations of the mean. This is accomplished by scaling the coefficient <span class="math inline">\(\beta\)</span> by the ratio of the standard deviation of <span class="math inline">\(x\)</span> over the standard deviation of <span class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[b = \beta*\left( \frac{sd_x}{sd_y} \right)\]</span></p>
<p>This coefficient has the interpretation that, for a 1 standard deviation change in <span class="math inline">\(x\)</span>, we expect a <span class="math inline">\(b\)</span> unit standard deviation change in <span class="math inline">\(y\)</span>.</p>
<p>This standardization can be achieved by Z-transforming the raw data, in which case <span class="math inline">\(b\)</span> is the (partial) correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> (see Chapter: Global Estimation). Scaling the raw data by subtracting the mean and dividing by the standard deviation lends this standardization its name.</p>
<p>Both <em>lavaan</em> and <em>piecewiseSEM</em> return scale-standardized coefficients. <em>lavaan</em> requires a different set of functions or arguments, while <em>piecewiseSEM</em> will do it by default using the functions <code>coefs</code>. <code>coefs</code> has the added benefit in that it can be called on any model object, not just an SEM.</p>
<p>Letâ€™s run an example:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(lavaan)</a></code></pre></div>
<pre><code>## This is lavaan 0.6-3</code></pre>
<pre><code>## lavaan is BETA software! Please report any bugs.</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">library</span>(piecewiseSEM)</a></code></pre></div>
<pre><code>## 
##   This is piecewiseSEM version 2.1.0
## 
## 
##   If you have used the package before, it is strongly recommended you read Section 3 of the vignette(&#39;piecewiseSEM&#39;) to familiarize yourself with the new syntax
## 
##   Questions or bugs can be addressed to &lt;LefcheckJ@si.edu&gt;</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">6</span>)</a>
<a class="sourceLine" id="cb6-2" data-line-number="2"></a>
<a class="sourceLine" id="cb6-3" data-line-number="3">data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">y =</span> <span class="kw">runif</span>(<span class="dv">100</span>), <span class="dt">x =</span> <span class="kw">runif</span>(<span class="dv">100</span>))</a>
<a class="sourceLine" id="cb6-4" data-line-number="4"></a>
<a class="sourceLine" id="cb6-5" data-line-number="5">xy_model &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> data)</a>
<a class="sourceLine" id="cb6-6" data-line-number="6"></a>
<a class="sourceLine" id="cb6-7" data-line-number="7"><span class="co"># perform manual standardization</span></a>
<a class="sourceLine" id="cb6-8" data-line-number="8">beta &lt;-<span class="st"> </span><span class="kw">summary</span>(xy_model)<span class="op">$</span>coefficients[<span class="dv">2</span>, <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb6-9" data-line-number="9"></a>
<a class="sourceLine" id="cb6-10" data-line-number="10">(beta_std &lt;-<span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>(<span class="kw">sd</span>(data<span class="op">$</span>x)<span class="op">/</span><span class="kw">sd</span>(data<span class="op">$</span>y)))</a></code></pre></div>
<pre><code>## [1] 0.09456659</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="co"># now retrieve with piecewiseSEM</span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2"><span class="kw">coefs</span>(xy_model)</a></code></pre></div>
<pre><code>##   Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate
## 1        y         x   0.0922     0.098 98     0.9404  0.3493       0.0946
##   
## 1</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="co"># and with lavaan</span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2">xy_formula &lt;-<span class="st"> &#39;y ~ x&#39;</span></a>
<a class="sourceLine" id="cb10-3" data-line-number="3"></a>
<a class="sourceLine" id="cb10-4" data-line-number="4">xy_sem &lt;-<span class="st"> </span><span class="kw">sem</span>(xy_formula, data)</a>
<a class="sourceLine" id="cb10-5" data-line-number="5"></a>
<a class="sourceLine" id="cb10-6" data-line-number="6"><span class="kw">standardizedsolution</span>(xy_sem)</a></code></pre></div>
<pre><code>##   lhs op rhs est.std    se      z pvalue ci.lower ci.upper
## 1   y  ~   x   0.095 0.099  0.956  0.339   -0.099    0.288
## 2   y ~~   y   0.991 0.019 52.991  0.000    0.954    1.028
## 3   x ~~   x   1.000 0.000     NA     NA    1.000    1.000</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="co"># also</span></a>
<a class="sourceLine" id="cb12-2" data-line-number="2"><span class="kw">summary</span>(xy_sem, <span class="dt">standardize =</span> T)</a></code></pre></div>
<pre><code>## lavaan 0.6-3 ended normally after 11 iterations
## 
##   Optimization method                           NLMINB
##   Number of free parameters                          2
## 
##   Number of observations                           100
## 
##   Estimator                                         ML
##   Model Fit Test Statistic                       0.000
##   Degrees of freedom                                 0
## 
## Parameter Estimates:
## 
##   Information                                 Expected
##   Information saturated (h1) model          Structured
##   Standard Errors                             Standard
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   y ~                                                                   
##     x                 0.092    0.097    0.950    0.342    0.092    0.095
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .y                 0.090    0.013    7.071    0.000    0.090    0.991</code></pre>
<p>In all 3 cases, we have achieved a scale-standardized coefficient of <span class="math inline">\(b = 0.095\)</span>. Thus, a 1 SD change in <span class="math inline">\(x\)</span> would result in a 0.095 SD change in <span class="math inline">\(y\)</span>.</p>
</div>
<div id="range-standardization" class="section level2">
<h2><span class="header-section-number">18.3</span> 1.3 Range Standardization</h2>
<p>An alternative to scale standardization is â€˜relevant rangeâ€™ standardization. This approach scales the coefficients over, as the name implies, some relevant range. Typically this is the full range of the data, in which case <span class="math inline">\(\beta\)</span> can be standardized as follows:</p>
<p><span class="math display">\[b = \beta * \frac{max(x) - min(x)}{max(y) - min(y)}\]</span></p>
<p>The interpretation for the coefficient would then be the expected proportional shift in <span class="math inline">\(y\)</span> along its range given a full shift along its range by <span class="math inline">\(x\)</span>.</p>
<p>At first, this might seem like a strange form of standardization, but it makes perfect sense in certain cases. For example, consider a binary predictor: 0, 1. In such a case, the relevant range-standardized coefficient is the expected shift in <span class="math inline">\(y\)</span> given the shift from one state (0) to another (1). Or consider a management target such as decreasing nutrient runoff by 10%. Would reducing fertilizer application by 10% of its range yield a 10% reduction in runoff? Such expressions are the currency of some, more applied realms.</p>
<p>Perhaps the best application of relevant ranges is in comparing coefficients within a model: rather than dealing in somewhat esoteric quantities of standard deviations, relevant range standardization simply asks which variable causes a greater shift in <span class="math inline">\(y\)</span> along its range. This is a much more digestable concept to most scientists. It may even provide a more fair comparison across the same paths fit to different datasets, if the ranges are roughly similar and/or encompassed in the others.</p>
<p>For a worked example, we have now entered fully into the realm of <em>piecewiseSEM</em>â€“it does not appear as if <em>lavaan</em> has integrated this functionality a of yet. Letâ€™s attempt to scale the results by hand, then compare to the output from <code>coefs</code> with the argument <code>standardize = &quot;range&quot;</code>:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="co">#by hand</span></a>
<a class="sourceLine" id="cb14-2" data-line-number="2">(beta_rr &lt;-<span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>(<span class="kw">max</span>(data<span class="op">$</span>x) <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(data<span class="op">$</span>x))<span class="op">/</span>(<span class="kw">max</span>(data<span class="op">$</span>y) <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(data<span class="op">$</span>y)))</a></code></pre></div>
<pre><code>## [1] 0.09806703</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw">coefs</span>(xy_model, <span class="dt">standardize =</span> <span class="st">&quot;range&quot;</span>)</a></code></pre></div>
<pre><code>##   Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate
## 1        y         x   0.0922     0.098 98     0.9404  0.3493       0.0981
##   
## 1</code></pre>
<p>In both cases, we obtain a <span class="math inline">\(b = 0.0981\)</span> suggesting that a full shift in <span class="math inline">\(x\)</span> along its range would only result in a shift of 10% along the range of <span class="math inline">\(y\)</span>.</p>
<p>Both scale and relevant range-standardization only apply when the response is normally-distributed. If not, we must make some assumptions in order to obtain standardized coefficients. Letâ€™s start with binomial responses.</p>
</div>
<div id="binomial-response-models" class="section level2">
<h2><span class="header-section-number">18.4</span> 1.4 Binomial Response Models</h2>
<p>Binomial responses are those that are binary (0, 1) such as success or failure, present or absent, and so on. What is unique about them is that they do not have a linear relationship with a predictor <span class="math inline">\(x\)</span>. Instead, they are best modeled using a sigmoidal curve. To demonstrate, letâ€™s generate some data, fit a binary model, and plot the predicted relationship:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">44</span>)</a>
<a class="sourceLine" id="cb18-2" data-line-number="2"></a>
<a class="sourceLine" id="cb18-3" data-line-number="3">x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">20</span>)</a>
<a class="sourceLine" id="cb18-4" data-line-number="4"></a>
<a class="sourceLine" id="cb18-5" data-line-number="5">x &lt;-<span class="st"> </span>x[<span class="kw">order</span>(x)]</a>
<a class="sourceLine" id="cb18-6" data-line-number="6"></a>
<a class="sourceLine" id="cb18-7" data-line-number="7">y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rbinom</span>(<span class="dv">10</span>, <span class="dv">1</span>, <span class="fl">0.8</span>), <span class="kw">rbinom</span>(<span class="dv">10</span>, <span class="dv">1</span>, <span class="fl">0.2</span>))</a>
<a class="sourceLine" id="cb18-8" data-line-number="8"></a>
<a class="sourceLine" id="cb18-9" data-line-number="9">glm_model &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y), <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb18-10" data-line-number="10"></a>
<a class="sourceLine" id="cb18-11" data-line-number="11">xpred &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(x), <span class="kw">max</span>(x), <span class="fl">0.01</span>)</a>
<a class="sourceLine" id="cb18-12" data-line-number="12"></a>
<a class="sourceLine" id="cb18-13" data-line-number="13">ypred &lt;-<span class="st"> </span><span class="kw">predict</span>(glm_model, <span class="kw">list</span>(<span class="dt">x =</span> xpred), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb18-14" data-line-number="14"></a>
<a class="sourceLine" id="cb18-15" data-line-number="15"><span class="kw">plot</span>(x, y)</a>
<a class="sourceLine" id="cb18-16" data-line-number="16"></a>
<a class="sourceLine" id="cb18-17" data-line-number="17"><span class="kw">lines</span>(xpred, ypred)</a></code></pre></div>
<p><img src="Coefficients_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Clearly these data are not linear, and modeling them as such would violate the assumptions of the test. Instead, as you can see, we instead fit them to a binomial distribution using a generalized linear model (GLM).</p>
<p>GLMs consist of three parts: (1) the random component, or the expected values of the response based on their underlying distribution, (2) the systematic component that represents the linear combination of predictors, and (3) the link function, which links the expected values of the response (random component) to the linear combination of predictors (systematic component).</p>
<p>Basically, the link functions take something inherently non-linear and attempts to linearize it. This can be shown by plotting the predictions on the link-scale:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1">ypred_link &lt;-<span class="st"> </span><span class="kw">predict</span>(glm_model, <span class="kw">list</span>(<span class="dt">x =</span> xpred), <span class="dt">type =</span> <span class="st">&quot;link&quot;</span>)</a>
<a class="sourceLine" id="cb19-2" data-line-number="2"></a>
<a class="sourceLine" id="cb19-3" data-line-number="3"><span class="kw">plot</span>(xpred, ypred_link)</a></code></pre></div>
<p><img src="Coefficients_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Note how the line is no longer sigmoidal, but straight!</p>
<p>For binomial responses, there are two kinds of link functions: logit and probit. Weâ€™ll focus on the logit link for now because its more common. With this link, the coefficients are in units of logits or the <em>log odds ratio</em>, which reflect the log of the probability of observing an outcome (1) relative to the probability of not observing it (0).</p>
<p>Often these coefficients are reverted to just the odds ratio by taking the exponent, which yields the proportional change in the probablity observing one outcome (1) with a unit change change in the predictor.</p>
<p>Say, for example, we have a coefficient <span class="math inline">\(\beta = -0.12\)</span>. A 1 unit change in <span class="math inline">\(x\)</span> would result in <span class="math inline">\(exp(-0.12) = 0.88 \times 100%\)</span> or 88% reduction in the odds of observing the outcome.</p>
<p>The problem is that (log) odds ratios themselves are not comparable across models, and its unclear how they might be standardized, since the coefficient is on the link (linear) scale, while the only variance we can compute is from the raw data, which is on the non-linear scale. Thus, we need to find some sway to obtain estimates of variance on the same scale as the coefficient.</p>
<p>One approach is to consider that for every value of <span class="math inline">\(x\)</span>, there is an underlying probability distribution of observing a 0 or a 1. The mean of these distributions is where a particular outcome is <em>most</em> likely. Letâ€™s say at low values of <span class="math inline">\(x\)</span> we observe 0, at at high values of <span class="math inline">\(x\)</span> we observe 1. If we order <span class="math inline">\(x\)</span>, the mean probabilities give rise to a linear increase in observing 1 with increasing <span class="math inline">\(x\)</span>. Here is an illustration of this phenomenon (from Long 1997):</p>
<div class="figure">
<img src="images/coefficients_latent_propensity.png" alt="latent propensity" />
<p class="caption">latent propensity</p>
</div>
<p>This linear but latent variable, which we call <span class="math inline">\(y^*\)</span>, is therefore related to the observed values of <span class="math inline">\(x\)</span> through a vector of linear coefficients <span class="math inline">\(\beta\)</span> as in any other linear model:</p>
<p><span class="math display">\[y^*_{i} = x_{i}\beta + \epsilon_{i}\]</span></p>
<p>The problem is, we can never observe this linear underlying or <em>latent propensity</em>, and so we must approximate it. At some value of <span class="math inline">\(x\)</span>, this probability is evenly split at 50/50: we call this cutpoint <span class="math inline">\(\tau\)</span>. Below <span class="math inline">\(\tau\)</span> we are more likely to observe 0 in our example, while above <span class="math inline">\(\tau\)</span> we are more likely to observe 1. We can relate <span class="math inline">\(y\)</span> to <span class="math inline">\(y^*\)</span> based on whether the observed values fall above or below this cutpoint.</p>
<p>Since latent variables are unobserved, we must also make some assumptions about their error variance. In the chapter on Latent Variable Modeling, we often fixed their error variance to 1. In this case, there are theoretically-derived error variances depending on the distribution and the link function: for the probit link, the error variance <span class="math inline">\(\epsilon = 1\)</span>, while for the logit link, <span class="math inline">\(\epsilon = \pi^2/3\)</span>, both for the binomial distribution.</p>
<p>Regardless of the type of standardization, we need to know about the range or variance of the response. With our knowledge of <span class="math inline">\(y^*_{i}\)</span> and the theoretical error variances, we have all the information needed to compute the variance on the link (linear) scale.</p>
<p>The variance in <span class="math inline">\(y^*\)</span> is the sum of the variance of the predictions (on the linear scale) <em>plus</em> the theoretical error variance. For a logit link, then:</p>
<p><span class="math display">\[\sigma_{y^*_{i}}^2 = \sigma_{x\beta}^2 + \pi^2/3\]</span></p>
<p>The square-root of this quantity gives the standard deviation of <span class="math inline">\(SD_{y^*}\)</span> on the linear scale for use in scale standardization, or alternately, the range of <span class="math inline">\(y^*\)</span> to use in relevant range standardization.</p>
<p>There is an alternate method to the â€˜latent theoretic approachâ€™, which relies on the proportion of variance explained, or <span class="math inline">\(R^2\)</span>. Here, we can express the <span class="math inline">\(R^2\)</span> as the variance of the predicted values (on the non-linear scale) over the variance of the observed values (also on the non-linear scale):</p>
<p><span class="math display">\[R^2 = \frac{\sigma_{\hat{y}}^2}{\sigma_{y}^2}\]</span></p>
<p>We can obtain the variance of the observed values as the variance of the predicted values (on the linear scale) over the value of <span class="math inline">\(R^2\)</span>. The standard deviation, of course, is the square-root of this value.</p>
<p>This method, called the <em>observation-empirical approach</em>, does not require the acknowledgement of any latent variables or theoretical error variances, but does require an acceptance of this is a valid measurement of <span class="math inline">\(R^2\)</span> (which some consider it not, as GLM estimation is based on deviance, not variance, and thus this statistic is not equivalent). It also does not provide a measure of the range of <span class="math inline">\(y\)</span> although we can assume, based on sampling theory, that is <span class="math inline">\(6 * \sigma_{y}\)</span>.</p>
<p>Letâ€™s revisit our earlier GLM example and construct standardized coefficients:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="co"># get beta from model</span></a>
<a class="sourceLine" id="cb20-2" data-line-number="2">beta &lt;-<span class="st"> </span><span class="kw">summary</span>(glm_model)<span class="op">$</span>coefficients[<span class="dv">2</span>, <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb20-3" data-line-number="3"></a>
<a class="sourceLine" id="cb20-4" data-line-number="4">preds &lt;-<span class="st"> </span><span class="kw">predict</span>(glm_model, <span class="dt">type =</span> <span class="st">&quot;link&quot;</span>) <span class="co"># linear predictions</span></a>
<a class="sourceLine" id="cb20-5" data-line-number="5"></a>
<a class="sourceLine" id="cb20-6" data-line-number="6"><span class="co"># latent theoretic</span></a>
<a class="sourceLine" id="cb20-7" data-line-number="7">sd.ystar &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(preds) <span class="op">+</span><span class="st"> </span>(pi<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">3</span>) <span class="co"># for default logit-link</span></a>
<a class="sourceLine" id="cb20-8" data-line-number="8"></a>
<a class="sourceLine" id="cb20-9" data-line-number="9">beta_lt &lt;-<span class="st"> </span>beta <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(x)<span class="op">/</span>sd.ystar</a>
<a class="sourceLine" id="cb20-10" data-line-number="10"></a>
<a class="sourceLine" id="cb20-11" data-line-number="11"><span class="co"># observation empirical</span></a>
<a class="sourceLine" id="cb20-12" data-line-number="12">R2 &lt;-<span class="st"> </span><span class="kw">cor</span>(y, <span class="kw">predict</span>(glm_model, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>))<span class="op">^</span><span class="dv">2</span> <span class="co"># non-linear predictions</span></a>
<a class="sourceLine" id="cb20-13" data-line-number="13"></a>
<a class="sourceLine" id="cb20-14" data-line-number="14">sd.yhat &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(preds)<span class="op">/</span>R2)</a>
<a class="sourceLine" id="cb20-15" data-line-number="15"></a>
<a class="sourceLine" id="cb20-16" data-line-number="16">beta_oe &lt;-<span class="st"> </span>beta <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(x)<span class="op">/</span>sd.yhat</a>
<a class="sourceLine" id="cb20-17" data-line-number="17"></a>
<a class="sourceLine" id="cb20-18" data-line-number="18"><span class="co"># obtain using `coefs`</span></a>
<a class="sourceLine" id="cb20-19" data-line-number="19"><span class="kw">coefs</span>(glm_model, <span class="dt">standardize.type =</span> <span class="st">&quot;latent.linear&quot;</span>); beta_lt</a></code></pre></div>
<pre><code>##   Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate
## 1        y         x  -2.0975    0.9664 18    -2.1703    0.03      -0.8122
##    
## 1 *</code></pre>
<pre><code>## [1] -0.8121808</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="kw">coefs</span>(glm_model, <span class="dt">standardize.type =</span> <span class="st">&quot;Menard.OE&quot;</span>); beta_oe</a></code></pre></div>
<pre><code>##   Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate
## 1        y         x  -2.0975    0.9664 18    -2.1703    0.03      -0.6566
##    
## 1 *</code></pre>
<pre><code>## [1] -0.6565602</code></pre>
<p>We see that both approaches produce coefficients, and they are the same as returned by the <code>coefs</code> function in <em>piecewiseSEM</em> (with the appropriate argument).</p>
<p>Youâ€™ll note that the observation-empirical approach yields a smaller coefficient than the latent-theoretic. This is because the former approach is influenced by the fact that it is based on the relationship between a linear approximation (predictions) of a non-linear variable (raw values), introducing a loss of information. The <em>latent theoretic approach</em> also suffers from a loss of information from use of a distribution-specific but theoretically-derived error variance, which may or may not approach the true error variance (which is unknowable). Either way, both kinds of standardization are not without their drawbacks, but both provide potentially useful information in being able to compare linear and now <em>linearized</em> standardized coefficients.</p>
</div>
<div id="scaling-to-other-non-normal-distributions" class="section level2">
<h2><span class="header-section-number">18.5</span> 1.5 Scaling to Other Non-Normal Distributions</h2>
<p>As it turns out, the latent-theoretic approach has one further benefit: we can extend it to other distributions (as they all have their own theoretical error variances) <em>and</em> mixed-effects models where we must also incorporate the random components.</p>
<p>[content to come]</p>
</div>
<div id="references" class="section level2">
<h2><span class="header-section-number">18.6</span> References</h2>
<p>Grace, J. B., Johnson, D. J., Lefcheck, J. S., &amp; Byrnes, J. E. (2018). Quantifying relative importance: computing standardized effects in models with binary outcomes. Ecosphere, 9(6), e02283.</p>
<p>Scott Long, J. (1997). Regression models for categorical and limited dependent variables. Advanced quantitative techniques in the social sciences, 7.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="why-structural-equation-modeling-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="global-estimation-and-piecewisesem.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
